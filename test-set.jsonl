{"id":"fde4f328-04fd-4c7e-b1b3-15ffdbc5aaa1","question":"What is self-refine prompting?","reference_answer":"Self-refine prompting is a prompt engineering technique where the model is prompted first to list the subproblems of a problem, and then solve them in sequence. This approach ensures that later subproblems can be solved with the help of answers to previous subproblems.","reference_context":"Document 73: For example, imagine a user prompts the model to write an essay on the effects of deforestation. The model might first generate facts like \"deforestation contributes to climate change\" and \"deforestation leads to loss of biodiversity.\" Then it would elaborate on the points in the essay.\nLeast-to-most prompting\nIn this prompt engineering technique, the model is prompted first to list the subproblems of a problem, and then solve them in sequence. This approach ensures that later subproblems can be solved with the help of answers to previous subproblems.\nFor example, imagine that a user prompts the model with a math problem like \"Solve for x in equation 2x + 3 = 11.\" The model might first list the subproblems as \"Subtract 3 from both sides\" and \"Divide by 2\". It would then solve them in sequence to get the final answer.\nSelf-refine prompting","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":73,"topic":"Prompt Engineering for Generative AI"}}
{"id":"b45092c5-dfc6-44e9-9c1e-3487e6aea362","question":"How can I sign up for a free AWS account?","reference_answer":"To sign up for a free AWS account, you can click on the 'Sign up' button on the AWS website. This will give you instant access to the AWS Free Tier, which provides free access to certain AWS services for 12 months.","reference_context":"Document 21: Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDocument 163: Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDocument 206: Instant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nDocument 52: Get started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":163,"topic":"AWS Services and Resources"}}
{"id":"3905dc59-dda7-4897-9e63-6cf799a157a7","question":"How can prompt engineering be used to enhance a model's creative abilities?","reference_answer":"Prompt engineering can be used to enhance a model's creative abilities in various scenarios. For instance, in writing scenarios, a writer could use a prompt-engineered model to help generate ideas for a story, such as listing possible characters, settings, and plot points. Or a graphic designer could prompt the model to generate a list of color palettes that evoke a certain emotion then create a design using that palette.","reference_context":"Document 68: Creativity involves generating new ideas, concepts, or solutions. Prompt engineering can be used to enhance a model's creative abilities in various scenarios.\nFor instance, in writing scenarios, a writer could use a prompt-engineered model to help generate ideas for a story. The writer may prompt the model to list possible characters, settings, and plot points then develop a story with those elements. Or a graphic designer could prompt the model to generate a list of color palettes that evoke a certain emotion then create a design using that palette.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":68,"topic":"Prompt Engineering for Generative AI"}}
{"id":"0260aa95-266d-440d-8140-df918ab98f10","question":"What is Cloud Computing?","reference_answer":"Cloud Computing refers to the delivery of computing services, including servers, storage, databases, networking, software, analytics, and intelligence, over the internet ('the cloud') to offer faster innovation, flexible resources, and economies of scale.","reference_context":"Document 8: What is Cloud Computing?\nCloud Computing Concepts Hub\nArtificial Intelligence\nGenerative AI\n\n\nWhat is RAG (Retrieval-Augmented Generation)?\n\n\nCreate an AWS Account\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n             Explore Free AI Offers \n           \n\n             Build, deploy, and run artificial intelligence applications in the cloud for free \n            \n\n\n\n\n\n\n\n\n\n\n\n             Check out Artificial Intelligence Services \n           \n\n             Innovate faster with the most comprehensive set of AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse AI Trainings","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":8,"topic":"Others"}}
{"id":"7107f40b-2d4a-44db-9046-6582c529007e","question":"What are the three main technologies that conversational AI works on?","reference_answer":"The three main technologies that conversational AI works on are natural language processing, natural language understanding, and natural language generation.","reference_context":"Document 132: Conversational AI works using three main technologies.\nNatural language processing\nNatural language processing (NLP) is a set of techniques and algorithms that allow machines to process, analyze, and understand human language. Human language has several features, like sarcasm, metaphors, sentence structure variations, and grammar and usage exceptions. Machine learning (ML) algorithms for NLP allow conversational AI models to continuously learn from vast textual data and recognize diverse linguistic patterns and nuances.\nRead about NLP \u00bb\nNatural language understanding\nNatural language understanding (NLU) is concerned with the comprehension aspect of the system. It ensures that conversational AI models process the language and understand user intent and context. For instance, the same sentence might have different meanings based on the context in which it's used.\nNLU uses machine learning to discern context, differentiate between meanings, and understand human conversation. This is especially crucial when virtual agents have to escalate complex queries to a human agent. NLU makes the transition smooth and based on a precise understanding of the user's need.\nNatural language generation","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":132,"topic":"Conversational AI"}}
{"id":"9f906168-0e82-4b3b-92c5-ee8f7ae3cebd","question":"What are some prompt engineering techniques that can be used to improve the quality of model responses?","reference_answer":"The passage describes three prompt engineering techniques that can be used to improve the quality of model responses:\n\n1. Explanation-based prompting, where the model is asked to provide an explanation for a given statement or fact.\n2. Complexity-based prompting, where the model performs multiple chain-of-thought rollouts and selects the most commonly reached conclusion.\n3. Generated knowledge prompting, where the model is first prompted to generate relevant facts before completing the final prompt.","reference_context":"Document 72: For example, if the question is \"Why is the sky blue?\" the model might first answer, \"The sky appears blue to the human eye because the short waves of blue light are scattered in all directions by the gases and particles in the Earth's atmosphere.\" It might then expand on parts of this explanation, such as why blue light is scattered more than other colors and what the Earth's atmosphere is composed of.\nComplexity-based prompting\nThis prompt-engineering technique involves performing several chain-of-thought rollouts. It chooses the rollouts with the longest chains of thought then chooses the most commonly reached conclusion.\nFor example, if the question is a complex math problem, the model might perform several rollouts, each involving multiple steps of calculations. It would consider the rollouts with the longest chain of thought, which for this example would be the most steps of calculations. The rollouts that reach a common conclusion with other rollouts would be selected as the final answer.\nGenerated knowledge prompting\nThis technique involves prompting the model to first generate relevant facts needed to complete the prompt. Then it proceeds to complete the prompt. This often results in higher completion quality as the model is conditioned on relevant facts.","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":72,"topic":"Prompt Engineering for Generative AI"}}
{"id":"eb152d11-b020-4a66-b217-b468cf2c27a6","question":"What are some examples of using conversational AI for data capture?","reference_answer":"Conversational AI can be used to collect essential user details or feedback, such as creating more humanlike interactions during an onboarding process, or gathering feedback about the customer journey through post-purchase or post-service chats.","reference_context":"Document 129: Conversational AI has several use cases in business processes and customer interactions. We\u2019ve grouped these use cases into four broad categories.\nInformational\nIn an informational context, conversational AI primarily answers customer inquiries or offers guidance on specific topics. For instance, your users can ask customer service chatbots about the weather, product details, or step-by-step recipe instructions. Another example would be AI-driven virtual assistants, which answer user queries with real-time information ranging from world facts to news updates.\nData capture\nYou can use conversational AI tools to collect essential user details or feedback. For instance, you can create more humanlike interactions during an onboarding process. Another scenario would be post-purchase or post-service chats where conversational interfaces gather feedback about the customer journey\u2014experiences, preferences, or areas of dissatisfaction.\nTransactional","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":129,"topic":"Conversational AI"}}
{"id":"460c5596-8c24-4092-84d4-80160a811fad","question":"What is the recommended first step when implementing generative AI solutions?","reference_answer":"It's best to start generative AI adoption with internal application development, focusing on process optimization and employee productivity.","reference_context":"Document 109: If your organization wants to implement generative AI solutions, consider the following best practices to enhance your efforts.\nBegin with internal applications\nIt\u2019s best to start generative AI adoption with internal application development, focusing on process optimization and employee productivity. You get a more controlled environment to test outcomes while building skills and understanding of the technology. You can test the models extensively and even customize them on internal knowledge sources.\nThis way, your customers have a much better experience when you eventually use the models for external applications.\nEnhance transparency\nClearly communicate about all generative AI applications and outputs so your users know they are interacting with AI and not humans. For instance, the AI can introduce itself as AI or AI-based search results can be marked and highlighted.\nThat way, your users can use their own discretion when they engage with the content. They may also be more proactive in dealing with any inaccuracies or hidden biases the underlying models may have because of their training data limitations.\nImplement security","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":109,"topic":"Generative AI Applications"}}
{"id":"80cbdd2a-aab0-4459-a94b-b3c7c641939a","question":"What are the key characteristics of the Jurassic-1 language model?","reference_answer":"Jurassic-1 is a 76-layer auto-regressive language model with 178 billion parameters, released in 2021. It generates human-like text and solves complex tasks, with performance comparable to GPT-3.","reference_context":"Document 201: Released in 2021, Jurassic-1 is a 76-layer auto-regressive language model with 178 billion parameters. Jurassic-1 generates human-like text and solves complex tasks. Its performance is comparable to GPT-3.\nIn March 2023, AI21 Labs released Jurrassic-2, which has improved instruction following and language capabilities.\nClaude\n\u00a0\nClaude 3.5 Sonnet\nAnthropic\u2019s most intelligent and advanced model, Claude 3.5 Sonnet, demonstrates exceptional capabilities across a diverse range of tasks and evaluations while also outperforming Claude 3 Opus.\nClaude 3 Opus\nOpus is a highly intelligent model with reliable performance on complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Use Opus to automate tasks, and accelerate research and development across a diverse range of use cases and industries.\nClaude 3 Haiku","conversation_history":[],"metadata":{"question_type":"simple","seed_document_id":201,"topic":"Foundation Models and Large Language Models"}}
{"id":"2031458f-ef1a-4a6f-b9e3-640f4948420e","question":"According to the pricing information provided in the context, what is the cost per 1,000 text units for the Denied topics feature offered as part of the Guardrail policy?","reference_answer":"The price per 1,000 text units for the Denied topics feature is $1.","reference_context":"Document 248: On-Demand pricing\n\n\n\n\n\nGuardrail policy* \nPrice per 1,000 text units** \n\n\nContent filters \n$0.75 \n\n\nDenied topics \n$1 \n\n\nContextual grounding check*** \n$0.1 \n\n\nSensitive information filter (PII) \n$0.1 \n\n\nSensitive information filter (regular expression)\u00a0 \nFree \n\n\nWord filters \nFree","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":248,"topic":"Cloud-Based AI Model Pricing"}}
{"id":"cbe12c57-f26e-42b1-93a1-db5fb7f7585a","question":"Considering the context provided, what are some potential real-world applications where foundation models could be leveraged to automate tasks and processes that require reasoning capabilities?","reference_answer":"Some potential applications of foundation models include automating tasks and processes that require reasoning capabilities, such as customer support, language translation, content generation, copywriting, image classification, high-resolution image creation and editing, document extraction, robotics, healthcare, and autonomous vehicles.","reference_context":"Document 192: Why is foundation modeling important?\n\nFoundation models are poised to significantly change the machine learning lifecycle. Although it currently costs millions of dollars to develop a foundation model from scratch, they\u2019re useful in the long run. It\u2019s faster and cheaper for data scientists to use pre-trained FMs to develop new ML applications rather than train unique ML models from the ground up.\nOne potential use is automating tasks and processes, especially those that require reasoning capabilities. Here are a few applications for foundation models:\n\nCustomer support\nLanguage translation\nContent generation\nCopywriting\nImage classification\nHigh-resolution image creation and editing\nDocument extraction\nRobotics\nHealthcare\nAutonomous vehicles\n\n\n\n\n\n\n\n\nHow do foundation models work?","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":192,"topic":"Foundation Models and Large Language Models"}}
{"id":"7f48d608-37d0-4504-935b-7c04fe0b251a","question":"What specific Generative AI services does AWS currently offer to its customers, and what capabilities do these services provide?","reference_answer":"AWS offers the most comprehensive set of Generative AI services to help customers innovate faster.","reference_context":"Document 150: Check out Generative AI on AWS \n           \n\n             Innovate faster with the most comprehensive set of Generative AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse Generative AI Trainings \n           \n\n             Get started on generative AI training with content built by AWS experts \n            \n\n\n\n\n\n\n\n\n\n\n\n             Read Generative AI Blogs \n           \n\n             Get the latest AWS generative AI product news and best practices\n\nDocument 169: Check out Generative AI on AWS \n           \n\n             Innovate faster with the most comprehensive set of Generative AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse Generative AI Trainings \n           \n\n             Get started on generative AI training with content built by AWS experts \n            \n\n\n\n\n\n\n\n\n\n\n\n             Read Generative AI Blogs \n           \n\n             Get the latest AWS generative AI product news and best practices\n\nDocument 212: Check out Generative AI on AWS \n           \n\n             Innovate faster with the most comprehensive set of Generative AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse Generative AI Trainings \n           \n\n             Get started on generative AI training with content built by AWS experts \n            \n\n\n\n\n\n\n\n\n\n\n\n             Read Generative AI Blogs \n           \n\n             Get the latest AWS generative AI product news and best practices\n\nDocument 188: Innovate faster with the most comprehensive set of Generative AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse Generative AI Trainings \n           \n\n             Get started on generative AI training with content built by AWS experts \n            \n\n\n\n\n\n\n\n\n\n\n\n             Read Generative AI Blogs \n           \n\n             Get the latest AWS generative AI product news and best practices","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":150,"topic":"AWS Generative AI Services"}}
{"id":"398b43ac-8e1d-448e-a85b-8655a3ee25a4","question":"What additional educational resources and product information can I access to learn more about the AWS services and features available to me?","reference_answer":"Check out additional product-related resources to innovate faster with AWS generative AI services.","reference_context":"Document 79: Check out additional product-related resources \n         \n Innovate faster with AWS generative AI services\u00a0\n\n\n\n\n\n\n\n\n           Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nDocument 182: Check out additional product-related resources \n         \n Innovate faster with AWS generative AI services\u00a0\n\n\n\n\n\n\n\n\n           Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nDocument 140: Next Steps on AWS\n\n\n\n\n\n\n\n\n           Check out additional product-related resources \n         \n Innovate faster with AWS generative AI services\u00a0\n\n\n\n\n\n\n\n\n           Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":79,"topic":"AWS Generative AI Services"}}
{"id":"928d5229-ecaa-426d-9123-75b628f70ba2","question":"What key characteristic of foundation models allows them to be applied to a diverse set of tasks with high performance, as opposed to traditional machine learning models that are typically designed for specific tasks?","reference_answer":"A unique feature of foundation models is their adaptability. These models can perform a wide range of disparate tasks with a high degree of accuracy based on input prompts.","reference_context":"Document 190: A unique feature of foundation models is their adaptability. These models can perform a wide range of disparate tasks with a high degree of accuracy based on input prompts. Some tasks include natural language processing (NLP), question answering, and image classification. The size and general-purpose nature of FMs make them different from traditional ML models, which typically perform specific tasks, like analyzing text for sentiment, classifying images, and forecasting trends.\nYou can use foundation models as base models for developing more specialized downstream applications. These models are the culmination of more than a decade of work that saw them increase in size and complexity.","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":190,"topic":"Foundation Models and Large Language Models"}}
{"id":"4a725f8f-da3b-49c7-a7ae-fff6cece521f","question":"Given that the input text to be summarized using the Llama 2 Chat (13B) model is 2,000 tokens and the desired output is 500 tokens, what is the total cost incurred for the API calls required to perform this summarization task, considering the pricing details provided in the context?","reference_answer":"The total cost incurred for the API calls to summarize 2K tokens of input text to 500 tokens using the Llama 2 Chat (13B) model is $0.002.","reference_context":"Document 256: An application developer makes the following API calls to Amazon Bedrock: a request to Meta\u2019s Llama 2 Chat (13B) model to summarize an input of 2K tokens of input text to an output of 500 tokens.\nTotal cost incurred = 2K tokens\/1000 * $0.00075 + 500 tokens\/1000 * $0.001 = $0.002\n\n Customization (fine-tuning) pricing\n\nAn application developer customizes the Llama 2 Pretrained (70B) model using 1000 tokens of data. After training, uses custom model provisioned throughput for 1 hour to evaluate the performance of the model. The fine-tuned model is stored for 1 month. After evaluation, the developer uses provisioned throughput (1mo commit) to host the customized model.\nMonthly cost incurred for fine-tuning = Fine tuning training ($0.00799 * 1000) + custom model storage per month ($1.95) + 1 hour of custom model inference ($23.50) = $33.44\nMonthly cost incurred for provisioned throughput (a 1-month commit) of custom model = $21.18\n\n Provisioned Throughput pricing","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":256,"topic":"Cloud-Based AI Model Pricing"}}
{"id":"a9c99b4b-7bf6-4aa4-ae11-a528e4c8d067","question":"What is the specific cost per human evaluation task for a model assessment on the Amazon Bedrock platform, given that you bring your own workforce to conduct the evaluation?","reference_answer":"For human-based evaluation where you bring your own workteam, you are charged for the model inference in the evaluation, and a charge of $0.21 per completed human task.","reference_context":"Document 235: With model evaluation on Amazon Bedrock you pay for what you use, with no volume commitments on the number of prompts or responses. For automatic evaluation, you only pay for the inference from your choice of model in the evaluation. The automatically-generated algorithmic scores are provided at no extra charge. For human-based evaluation where you bring your own workteam, you are charged for the model inference in the evaluation, and a charge of $0.21 per completed human task. A human task is defined as an instance of a human worker submitting an evaluation of a single prompt and its associated inference responses in the human evaluation user interface. The price is the same whether you have one or two models in your evaluation job and also the same regardless of how many evaluation metrics and rating methods you include. The charges for the human tasks will appear under the Amazon SageMaker section in your AWS bill and are the same for all AWS Regions. There is no separate charge for the workforce, as the workforce is supplied by you. For an evaluation managed by AWS, pricing is customized for your evaluation needs in a private engagement while working with the AWS expert evaluations team. \n\n\n\n\n\n\n\n\n\n\n\n Powerful tools to build at no extra charge","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":235,"topic":"Cloud-Based AI Model Pricing"}}
{"id":"b3809334-ef5e-4231-a88a-618ccd21708d","question":"Considering the context provided, which key concepts or characteristics of cloud computing are described in detail to help a user understand this technology?","reference_answer":"Cloud computing refers to the on-demand delivery of computing services, such as storage, processing power, databases, and software, over the internet. Instead of maintaining physical hardware and software, cloud computing allows users to access and utilize these resources as needed, without the need for local infrastructure or management.","reference_context":"Document 149: Products  \n  Solutions  \n  Pricing  \n  Introduction to AWS  \n  Getting Started  \n  Documentation  \n  Training and Certification  \n  Developer Center  \n  Customer Success  \n  Partner Network  \n  AWS Marketplace  \n  Support  \n  AWS re:Post  \n  Log into Console  \n  Download the Mobile App  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Cloud Computing?\nCloud Computing Concepts Hub\nGenerative AI\n\n\nWhat is Stable Diffusion?\n\n\nCreate an AWS Account\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n             Explore Generative AI Services \n           \n\n             Build, deploy, and run generative AI applications on AWS","conversation_history":[],"metadata":{"question_type":"complex","seed_document_id":149,"topic":"Others"}}
{"id":"dfee8452-3a7a-4b70-8283-a606fab97a81","question":"What is the pricing for the Claude 3 Sonnet model's output tokens in the Asia Pacific (Sydney) region, if the customer has a disability that requires specialized accommodations?","reference_answer":"$0.015","reference_context":"Document 239: Claude 3 Sonnet \n$0.003 \n$0.015 \n\n\nClaude 3\u00a0Haiku \n$0.00025 \n$0.00125 \n\n\n\n\n\nRegion: Asia Pacific (Sydney) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nClaude 3 Sonnet \n$0.003 \n$0.015 \n\n\nClaude 3\u00a0Haiku \n$0.00025 \n$0.00125 \n\n\n\n\n\nRegion: Asia Pacific (Tokyo) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nClaude Instant \n$0.0008 \n$0.0024 \n\n\nClaude 2.0\/2.1 \n$0.008 \n$0.024 \n\n\nClaude 3 Haiku \n$0.00025 \n$0.00125 \n\n\nClaude 3.5 Sonnet \n$0.003 \n$0.015\n\nDocument 238: Claude 3 Sonnet \n$0.003 \n$0.015 \n\n\nClaude 3\u00a0Haiku \n$0.00025 \n$0.00125 \n\n\n\n\n\nRegion:\u00a0South America (Sao Paolo) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nClaude 3 Sonnet \n$0.003 \n$0.015 \n\n\nClaude 3\u00a0Haiku \n$0.00025 \n$0.00125 \n\n\n\n\n\nRegion:\u00a0Canada (Central) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nClaude 3 Sonnet \n$0.003 \n$0.015 \n\n\nClaude 3\u00a0Haiku \n$0.00025 \n$0.00125 \n\n\n\n\n\nRegion: Asia Pacific (Mumbai) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\nDocument 240: Region: Asia Pacific (Singapore) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nClaude Instant \n$0.0008 \n$0.0024 \n\n\nClaude 2.0\/2.1 \n$0.008 \n$0.024 \n\n\nClaude 3 Haiku \n$0.00025 \n$0.00125 \n\n\nClaude 3.5 Sonnet \n$0.003 \n$0.015 \n\n\n\n\n\nRegion: Europe (Paris) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nClaude 3 Sonnet \n$0.003 \n$0.015 \n\n\nClaude 3\u00a0Haiku \n$0.00025 \n$0.00125 \n\n\n\n\n\nRegion: Europe (Frankfurt) \n\n\n\n\n\nAnthropic models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":239,"distracting_context":"The next step is to perform a relevancy search. The user query is converted to a vector representation and matched with the vector databases. For example, consider a smart chatbot that can answer human resource questions for an organization. If an employee searches, \"How much annual leave do I have?\" the system will retrieve annual leave policy documents alongside the individual employee's past leave record. These specific documents will be returned because they are highly-relevant to what the employee has input. The relevancy was calculated and established using mathematical vector calculations and representations.\nAugment the LLM prompt\nNext, the RAG model augments the user input (or prompts) by adding the relevant retrieved data in context. This step uses prompt engineering techniques to communicate effectively with the LLM. The augmented prompt allows the large language models to generate an accurate answer to user queries.\nUpdate external data","topic":"Cloud-Based AI Model Pricing"}}
{"id":"eb94266c-daba-466a-9eca-f17dc65aa38a","question":"What types of AI services does the Amazon Bedrock User Guide mention that can be used to build AI applications?","reference_answer":"The context mentions that Amazon offers a comprehensive set of AI services to help customers innovate faster.","reference_context":"Document 27: Check out Artificial Intelligence Services \n           \n\n             Innovate faster with the most comprehensive set of AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse AI Trainings \n           \n\n             Build in-demand AI skills with course, tutorial, and resources \n            \n\n\n\n\n\n\n\n\n\n\n\n             Read AI & Machine Learning Blogs \n           \n\n             Read about the latest AWS AI & ML product news and best practices","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":27,"distracting_context":"What are the key components of AI application architecture?\n\nArtificial intelligence architecture consists of three core layers. All the layers run on IT infrastructure that provides the necessary compute and memory resources for the AI to run.\nLayer 1: Data layer\nAI is built upon various technologies like machine learning, natural language processing, and image recognition. Central to these technologies is data, which forms the foundational layer of AI. This layer primarily focuses on preparing the data for AI applications.\u00a0\nLayer 2: Model layer\nOrganizations typically select from one among many existing foundation models or LLMs. They customize it by different techniques that feed the model with the latest data the organization wants. This layer is pivotal for the AI system's decision-making capabilities.\u00a0\nLayer 3: Application layer\nThe third layer is the application layer, the customer-facing part of AI architecture. You can ask AI systems to complete specific tasks, generate information, provide information, or make data-driven decisions. The application layer allows end users to interact with AI systems.\n\n\n\n\n\n\n\nWhat are the challenges in artificial intelligence implementation?","topic":"AWS Generative AI Services"}}
{"id":"20be0515-598b-4ee3-bd03-fc880f68438c","question":"What are the different ways an engineering student with a disability can contact AWS support to get assistance with complex technical issues?","reference_answer":"According to the context, there are several ways to contact AWS support, including filing a support ticket, using the AWS re:Post forum, and accessing the Knowledge Center. The context also mentions that users can get expert help through these channels.","reference_context":"Document 207: Contact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account \n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n         Amazon is an Equal Opportunity Employer: \n         Minority \/ Women \/ Disability \/ Veteran \/ Gender Identity \/ Sexual Orientation \/ Age.\n\n\n\n\n\n\n\n\n\nLanguage\n\u0639\u0631\u0628\u064a\nBahasa Indonesia\nDeutsch\nEnglish\nEspa\u00f1ol\nFran\u00e7ais\nItaliano\nPortugu\u00eas\nTi\u1ebfng Vi\u1ec7t\nT\u00fcrk\u00e7e\n\u03a1\u0443\u0441\u0441\u043a\u0438\u0439\n\u0e44\u0e17\u0e22\n\u65e5\u672c\u8a9e\n\ud55c\uad6d\uc5b4\n\u4e2d\u6587 (\u7b80\u4f53)\n\u4e2d\u6587 (\u7e41\u9ad4)","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":207,"distracting_context":"Many industries grapple with complex problems that require analyzing millions of past transactions and discovering hidden patterns\u2014for example, fraud detection, machinery maintenance, and product innovation. AI systems can collect and analyze data at scale from various sources to support complex human decision-making. For example, answering when a particular mechanical component should be repaired requires analyzing machine data like temperature and speed alongside usage reports and past maintenance schedules. Artificial intelligence can take all this data, discover hidden connections, and suggest optimal maintenance schedules for significant cost savings. Similarly, it can support more complex fields like genomic research and drug discovery.\nCreate new customer experiences\nOrganizations use artificial intelligence to create customized customer experiences with greater security and speed. For example, AI systems can combine customer profile data, such as preferences and digital behavior, with other product or service data to create personalized reports, recommendations, and action plans. Customers can find real-time answers to questions or discover new products and services without waiting for live customer support. For example, Lonely Planet used artificial intelligence to generate curated travel itineraries for customers while cutting itinerary generation costs by 80%.\nFind more AI use cases and benefits \u00bb","topic":"AWS Services and Resources"}}
{"id":"6781a6a1-1240-4e37-b5e4-2ccb90691b79","question":"What payment methods does Amazon Bedrock accept for on-demand pricing of model evaluation jobs in the US East (N. Virginia) AWS Region?","reference_answer":"We accept a variety of payment methods to provide our customers with a convenient and secure shopping experience. You can make a purchase using major credit and debit cards, including Visa, Mastercard, American Express, and Discover. We also offer the option to pay with popular digital wallets such as PayPal and Google Pay. For added flexibility, you can choose to complete your order using bank transfers or wire transfers.","reference_context":"Document 131: How does conversational AI work?","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":131,"distracting_context":"On-demand pricing An application developer submits a dataset for human-based model evaluation using Anthropic Claude 2.1 and Anthropic Claude Instant in the US East (N. Virginia) AWS Region. \nThe dataset contains 50 prompts, and the developer requires one worker to rate each prompt-response set (configurable in the evaluation job creation as \u201cworkers per prompt\u201d parameter).  There will be 50 tasks in this evaluation job (one task for each prompt-response set per each worker). The 50 prompts combine to 5000 input tokens, and the associated responses combine to 15,000 tokens for Anthropic Claude Instant and 20,000 tokens for Anthropic Claude 2.1.  The following charges are incurred for this model evaluation job:\n\n\n\n\n\nItem\nNumber of input tokens\nPrice per 1000 input tokens\nCost of input\nNumber of output tokens\nPrice per 1000 output tokens\nCost of output\nNumber of human tasks\nPrice per human task\nCost of human tasks\nTotal\n\n\nClaude Instant Inference\n5000\n$0.0008\n$0.004\n15000\n$0.0024\n$0.036\n\u00a0\n\u00a0\n\u00a0\n$0.04","topic":"Conversational AI"}}
{"id":"26edc13e-bc39-49ba-929b-a7d02ccef3d0","question":"In the context of a transactional interface, how could conversational AI be leveraged to assist customers with disabilities in completing purchases or other transactions?","reference_answer":"In a transactional context, conversational AI can be used to enable users to complete purchases or other transactions. For example, conversational AI could be used to allow customers to place orders, make payments, or schedule appointments through a natural language interface.","reference_context":"Document 129: Conversational AI has several use cases in business processes and customer interactions. We\u2019ve grouped these use cases into four broad categories.\nInformational\nIn an informational context, conversational AI primarily answers customer inquiries or offers guidance on specific topics. For instance, your users can ask customer service chatbots about the weather, product details, or step-by-step recipe instructions. Another example would be AI-driven virtual assistants, which answer user queries with real-time information ranging from world facts to news updates.\nData capture\nYou can use conversational AI tools to collect essential user details or feedback. For instance, you can create more humanlike interactions during an onboarding process. Another scenario would be post-purchase or post-service chats where conversational interfaces gather feedback about the customer journey\u2014experiences, preferences, or areas of dissatisfaction.\nTransactional","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":129,"distracting_context":"How does Retrieval-Augmented Generation work?","topic":"Conversational AI"}}
{"id":"2f573a68-37f0-4f22-84b8-2e34090a55a8","question":"If I want to use both Agents for Amazon Bedrock and Knowledge Bases for Amazon Bedrock, how will the pricing model work in terms of the specific models and vector databases I use?","reference_answer":"When using Agents for Amazon Bedrock and Knowledge Bases for Amazon Bedrock, you are only charged for the models and the vector databases you use with these capabilities.","reference_context":"Document 236: When using Agents for Amazon Bedrock and Knowledge Bases for Amazon Bedrock, you are only charged for the models and the vector databases you use with these capabilities. \n\n\n\n\n\n\n\n Pricing breakdown\n\nPricing is dependent on the modality, provider, and model. Please select the model provider to see detailed pricing. \n\n\nAmazon Bedrock offers select foundation models (FMs) from leading AI providers like Anthropic, Meta, Mistral AI, and Amazon for batch inference at a 50% lower price compared to on-demand inference pricing. Please refer to model list here.\n\n\n\n\n\n\n\n AI21 Labs\n\nOn-Demand pricing \n\n\n\n\n\nAI21 Labs models\nPrice per 1,000 input tokens\nPrice per 1,000 output tokens\n\n\nJurassic-2 Mid \n$0.0125 \n$0.0125 \n\n\nJurassic-2 Ultra \n$0.0188 \n$0.0188 \n\n\nJamba-Instruct \n$0.0005 \n$0.0007 \n\n\n\n\n\n\n\n\n\n\n Amazon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Anthropic","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":236,"distracting_context":"What Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account","topic":"Cloud-Based AI Model Pricing"}}
{"id":"87c910a4-614c-4600-9e34-54657cb8659f","question":"How can Stable Diffusion be leveraged by prompt engineers to create more effective and user-friendly AI applications?","reference_answer":"Stable Diffusion is a powerful text-to-image generation model that can create unique and high-quality images based on textual descriptions. It is capable of generating a wide variety of images, from realistic scenes to abstract art, by interpreting and translating the input text into a corresponding visual representation.","reference_context":"Document 159: What can Stable Diffusion do?","conversation_history":[],"metadata":{"question_type":"distracting element","seed_document_id":159,"distracting_context":"Prompt engineering jobs have increased significantly since the launch of generative AI. Prompt engineers bridge the gap between your end users and the large language model. They identify scripts and templates that your users can customize and complete to get the best result from the language models. These engineers experiment with different types of inputs to build a prompt library that application developers can reuse in different scenarios.\nPrompt engineering makes AI applications more efficient and effective. Application developers typically encapsulate open-ended user input inside a prompt before passing it to the AI model.\nFor example, consider AI chatbots. A user may enter an incomplete problem statement like, \"Where to purchase a shirt.\" Internally, the application's code uses an engineered prompt that says, \"You are a sales assistant for a clothing company. A user, based in Alabama, United States, is asking you where to purchase a shirt. Respond with the three nearest store locations that currently stock a shirt.\" The chatbot then generates more relevant and accurate information.\nNext, we discuss some benefits of prompt engineering.\nGreater developer control","topic":"Stable Diffusion"}}
{"id":"59ad9d70-7126-42f7-a258-727f5d1fbed4","question":"As a researcher interested in leveraging advanced language models for my work, I'd love to learn more about the key capabilities of large models like GPT-3, ChatGPT, and Jurassic-1. Could you please explain what makes these models so powerful and versatile?","reference_answer":"Large language models like GPT-3, ChatGPT, and Jurassic-1 have the following key capabilities:\n\n- They have very large parameter sizes, ranging from 175 billion parameters for GPT-3 to 178 billion parameters for Jurassic-1, allowing them to identify patterns from large amounts of data.\n- They can generate natural and readable output, demonstrating conversational capabilities.\n- They can work with very long inputs, up to 100K tokens for Claude 2, allowing them to process large amounts of technical documentation or even entire books.\n- They have large vocabularies, with Jurassic-1 having a token vocabulary of 250,000 word parts.\n- Some models like Cohere's Command can work in more than 100 different languages.\n- They come with APIs that allow developers to create unique generative AI applications.","reference_context":"Document 174: Open AI's GPT-3 model has 175 billion parameters. Its cousin, ChatGPT, can identify patterns from data and generate natural and readable output. While we don\u2019t know the size of Claude 2, it can take inputs up to 100K tokens in each prompt, which means it can work over hundreds of pages of technical documentation or even an entire book.\nAI21 Labs\u2019 Jurassic-1 model has 178 billion parameters and a token vocabulary of 250,000-word parts and similar conversational capabilities.\nCohere\u2019s Command model has similar capabilities and can work in more than 100 different languages.\nLightOn's Paradigm offers foundation models with claimed capabilities that exceed those of GPT-3. All these LLMs come with APIs that allow developers to create unique generative AI applications.\n\nRead more about\u00a0generative AI\u00a0\u00bb\nRead more about\u00a0foundation models\u00a0\u00bb\n\n\n\n\n\n\n\nHow do large language models work?","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":174,"situational_context":"A user is studying the capabilities of advanced language models to understand how they can be leveraged for their own research or application development.","topic":"Foundation Models and Large Language Models"}}
{"id":"28784df2-b6f9-4a91-8f0c-ca47aab344e8","question":"Hi there, I'm an application developer working on a text summarization project and I'm trying to understand the costs involved. Could you please let me know what the on-demand pricing is for the Mistral AI model? I want to make sure I have a good handle on the pricing options before moving forward.","reference_answer":"The context does not provide any information about the on-demand pricing for the Mistral AI model. The context only mentions the total monthly cost incurred for using 1 model unit of Meta Llama 2 with a 1-month commitment, which is $15,757.92.","reference_context":"Document 257: An application developer buys one model unit of Meta Llama 2 with a 1-month commitment for their text summarization use case.\nTotal monthly cost incurred = 1 model unit * $21.18 * 24 hours * 31 days = $15,757.92\n\n\n \n   Mistral AI \n\n\n On-Demand pricing","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":257,"situational_context":"An application developer is trying to understand the costs associated with utilizing the Meta Llama 2 model for their text summarization project.","topic":"Cloud-Based AI Model Pricing"}}
{"id":"65260942-9cec-4b4c-8f6a-476b9774315d","question":"As an AWS developer working on a new project, I'm reviewing the Amazon Bedrock User Guide to understand the supported programming languages. Could you please let me know what programming languages are supported on AWS?","reference_answer":"The programming languages supported on AWS include .NET, Python, Java, PHP, and JavaScript.","reference_context":"Document 80: Getting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account \n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n         Amazon is an Equal Opportunity Employer: \n         Minority \/ Women \/ Disability \/ Veteran \/ Gender Identity \/ Sexual Orientation \/ Age.\n\nDocument 183: Getting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account \n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n         Amazon is an Equal Opportunity Employer: \n         Minority \/ Women \/ Disability \/ Veteran \/ Gender Identity \/ Sexual Orientation \/ Age.\n\nDocument 22: Developer Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account \n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n         Amazon is an Equal Opportunity Employer: \n         Minority \/ Women \/ Disability \/ Veteran \/ Gender Identity \/ Sexual Orientation \/ Age.\n\nDocument 164: Developer Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account \n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n\n         Amazon is an Equal Opportunity Employer: \n         Minority \/ Women \/ Disability \/ Veteran \/ Gender Identity \/ Sexual Orientation \/ Age.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":80,"situational_context":"An AWS developer is reviewing the Amazon Bedrock User Guide to gain a better understanding of the product's features and capabilities before starting a new project.","topic":"AWS Services and Resources"}}
{"id":"0804c3d1-9e4b-4460-a2b7-f14f8e2c016d","question":"Hi there, I'm a student interested in learning more about cloud computing and how it works. Could you please explain what cloud computing is and how it differs from traditional computing models?","reference_answer":"Cloud Computing refers to the delivery of computing services - including servers, storage, databases, networking, software, analytics, and intelligence - over the internet ('the cloud') to offer faster innovation, flexible resources, and economies of scale.","reference_context":"Document 8: What is Cloud Computing?\nCloud Computing Concepts Hub\nArtificial Intelligence\nGenerative AI\n\n\nWhat is RAG (Retrieval-Augmented Generation)?\n\n\nCreate an AWS Account\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n             Explore Free AI Offers \n           \n\n             Build, deploy, and run artificial intelligence applications in the cloud for free \n            \n\n\n\n\n\n\n\n\n\n\n\n             Check out Artificial Intelligence Services \n           \n\n             Innovate faster with the most comprehensive set of AI services \n            \n\n\n\n\n\n\n\n\n\n\n\n             Browse AI Trainings","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":8,"situational_context":"A curious student is seeking information about cloud computing and its applications, hoping to learn more about the technology and its potential for their future studies and career.","topic":"Others"}}
{"id":"65c1eab1-5891-42d1-8fac-a41e2f9a132c","question":"As a prompt engineer looking to optimize business processes across our organization, how can I use prompt engineering to create more flexible AI tools that can be rapidly deployed at scale?","reference_answer":"Prompt engineering can create prompts with domain-neutral instructions highlighting logical links and broad patterns, which allows organizations to rapidly reuse the prompts across the enterprise to expand their AI investments and create more flexible tools at scale.","reference_context":"Document 65: Higher levels of abstraction improve AI models and allow organizations to create more flexible tools at scale. A prompt engineer can create prompts with domain-neutral instructions highlighting logical links and broad patterns. Organizations can rapidly reuse the prompts across the enterprise to expand their AI investments.\nFor example, to find opportunities for process optimization, the prompt engineer can create different prompts that train the AI model to find inefficiencies using broad signals rather than context-specific data. The prompts can then be used for diverse processes and business units.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":65,"situational_context":"A prompt engineer is exploring ways to optimize business processes across an organization by creating reusable AI model prompts that focus on identifying broad patterns and inefficiencies.","topic":"Prompt Engineering for Generative AI"}}
{"id":"e0e5e6cf-c9c9-4f7d-afd3-d3f268fcf0e8","question":"As a professional looking to optimize internal processes and increase employee productivity, what would you say is one best practice for implementing generative AI solutions?","reference_answer":"One best practice for implementing generative AI solutions is to begin with internal applications, focusing on process optimization and employee productivity. This provides a more controlled environment to test outcomes while building skills and understanding of the technology.","reference_context":"Document 109: If your organization wants to implement generative AI solutions, consider the following best practices to enhance your efforts.\nBegin with internal applications\nIt\u2019s best to start generative AI adoption with internal application development, focusing on process optimization and employee productivity. You get a more controlled environment to test outcomes while building skills and understanding of the technology. You can test the models extensively and even customize them on internal knowledge sources.\nThis way, your customers have a much better experience when you eventually use the models for external applications.\nEnhance transparency\nClearly communicate about all generative AI applications and outputs so your users know they are interacting with AI and not humans. For instance, the AI can introduce itself as AI or AI-based search results can be marked and highlighted.\nThat way, your users can use their own discretion when they engage with the content. They may also be more proactive in dealing with any inaccuracies or hidden biases the underlying models may have because of their training data limitations.\nImplement security","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":109,"situational_context":"A professional researching ways to optimize internal processes and increase employee productivity through generative AI solutions.","topic":"Generative AI Applications"}}
{"id":"b0204082-445f-48bf-83a6-5b70506ae4f0","question":"Hi there, I'm an application developer using the Amazon Bedrock service for a text summarization use case. I'm trying to understand the monthly costs involved for using the two Amazon Titan Text Express model units with a 1-month commitment. Could you please let me know the total monthly cost I would incur for this setup?","reference_answer":"$27,379.20","reference_context":"Document 252: An application developer buys two model units of Amazon Titan Text Express with a 1-month commitment for their text summarization use case.\nTotal monthly cost incurred = 2 model units * $18.40\/hour * 24 hours * 31 days = $27,379.20\nAn application developer buys one model unit of the base Amazon Titan Image Generator model with a 1-month commitment.\nTotal cost incurred = 1 model unit * $16.20 * 24 hours * 31 days = $12,052.80\n\n\n \n   Anthropic \n\n\n On-Demand pricing\n\nAn application developer makes the following API calls to Amazon Bedrock in the US West (Oregon) Region: a request to Anthropic\u2019s Claude model to summarize an input of 11K tokens of input text to an output of 4K tokens.\nTotal cost incurred = 11K tokens\/1000 * $0.008 + 4K tokens\/1000 * $0.024 = $0.088 + $0.096 = $0.184 \n\n Provisioned Throughput pricing","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":252,"situational_context":"The application developer is using the Amazon Bedrock service to summarize a significant amount of text for their text summarization use case, incurring significant monthly costs for the Titan Text Express and Titan Image Generator models.","topic":"Cloud-Based AI Model Pricing"}}
{"id":"a6f56730-a38e-4ae6-8159-9760108de071","question":"Hi there, I'm an engineer working on an exciting new project and I'm doing some research on foundation models to help accelerate my work. Could you tell me, what is the notable feature of GPT-1?","reference_answer":"A notable feature of GPT-1 is the ability to do zero-shot learning.","reference_context":"Document 198: The number and size of foundation models on the market have grown at a rapid pace. There are now dozens of models available. Here is a list of prominent foundation models released since 2018.\nBERT\nReleased in 2018, Bidirectional Encoder Representations from Transformers (BERT) was one of the first foundation models. BERT is a bidirectional model that analyzes the context of a complete sequence then makes a prediction. It was trained on a plain text corpus and Wikipedia using 3.3 billion tokens (words) and 340 million parameters. BERT can answer questions, predict sentences, and translate texts.\nGPT\nThe Generative Pre-trained Transformer (GPT) model was developed by OpenAI in 2018. It uses a 12-layer transformer decoder with a self-attention mechanism. And it was trained on the BookCorpus dataset, which holds over 11,000 free novels. A notable feature of GPT-1 is the ability to do zero-shot learning.","conversation_history":[],"metadata":{"question_type":"situational","seed_document_id":198,"situational_context":"A busy engineer is researching foundation models to accelerate their work on an exciting new project.","topic":"Foundation Models and Large Language Models"}}
{"id":"fe5966cf-e51e-40c4-9776-5b3223e17d0c","question":"How many image-text pairs did the application developer use to customize the Amazon Titan Image Generator model, and what is the monthly cost incurred for fine-tuning the customized model?","reference_answer":"The application developer customized the Amazon Titan Image Generator model using 1000 image-text pairs, and the monthly cost incurred for fine-tuning the customized model is $182.95, which includes the cost of fine-tuning training ($160), custom model storage per month ($1.95), and 1 hour of custom model inference ($21).","reference_context":"Document 251: An application developer customizes an Amazon Titan Image Generator model using 1000 image-text pairs. After training, the developer uses custom model provisioned throughput for 1 hour to evaluate the performance of the model. The fine-tuned model is stored for 1 month. After evaluation, the developer uses provisioned throughput (1-month commitment term) to host the customized model.\nMonthly cost incurred for fine-tuning = fine-tuning training ($.005 * 500 * 64), where $0.005 is the price per image seen, 500 is the number of steps, and 64 is the batch size, + custom model storage per month ($1.95) + 1 hour of custom model inference ($21) = $160 + $1.95 + 21 = $182.95 \n\n Provisioned Throughput pricing","conversation_history":[],"metadata":{"question_type":"double","original_questions":[{"question":"How many image-text pairs did the application developer use to customize the Amazon Titan Image Generator model?","answer":"The application developer customized the Amazon Titan Image Generator model using 1000 image-text pairs."},{"question":"What is the monthly cost incurred for fine-tuning the customized model?","answer":"The monthly cost incurred for fine-tuning the customized model is $182.95, which includes the cost of fine-tuning training ($160), custom model storage per month ($1.95), and 1 hour of custom model inference ($21)."}],"seed_document_id":251,"topic":"Cloud-Based AI Model Pricing"}}
{"id":"54e32ee5-32ac-40af-9d91-05f727144faf","question":"How can it do that?","reference_answer":"Amazon Bedrock is the easiest way to build and scale generative AI applications with foundation models. Amazon Bedrock is a fully managed service that makes leading foundation models including Stable Diffusion available through an API, so you can choose from various FMs to find the model that's best suited for your use case. With Bedrock, you can speed up developing and deploying scalable, reliable, and secure generative AI applications without managing infrastructure. Additionally, Amazon SageMaker JumpStart provides access to hundreds of foundation models, including Stable Diffusion.","reference_context":"Document 162: How can AWS help with Stable Diffusion?\n\nAmazon Bedrock is the easiest way to build and scale generative AI applications with foundation models. Amazon Bedrock is a fully managed service that makes leading foundation models including Stable Diffusion available through an API, so you can choose from various FMs to find the model that's best suited for your use case.\u00a0With Bedrock, you can speed up developing and deploying scalable, reliable, and secure generative AI applications without managing infrastructure.\nAmazon SageMaker JumpStart, which is a ML hub offering models, algorithms, and solutions, provides access to hundreds of foundation models, including top performing publicly available foundation models such as Stable Diffusion. New foundation models continue to be added, including Stable Diffusion XL 1.0, the latest version of the image generation model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next Steps on AWS\n\n\n\n\n\n\n\n\n           Check out additional product-related resources \n         \n Innovate faster with AWS generative AI services","conversation_history":[{"role":"user","content":"I am interested in using AWS to help with Stable Diffusion."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":162,"topic":"Others"}}
{"id":"9b3576c7-a8db-4110-baa0-d450fd8cdec1","question":"What is the underlying mechanism behind this technology?","reference_answer":"The context does not provide any information about how GPT (Generative Pre-trained Transformer) works. The given text does not contain any details about the GPT language model or its underlying architecture and training process.","reference_context":"Document 217: How does GPT work?","conversation_history":[{"role":"user","content":"I'm interested in understanding how GPT works."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":217,"topic":"Generative Pre-Trained Transformer (GPT) AI"}}
{"id":"f84b22f9-8e89-401a-9bf8-e64313afc523","question":"What are the total charges incurred for this job?","reference_answer":"The total charges incurred for the model evaluation job are:\n\nItem\nNumber of input tokens\nPrice per 1000 input tokens\nCost of input\nNumber of output tokens\nPrice per 1000 output tokens\nCost of output\nNumber of human tasks\nPrice per human task\nCost of human tasks\nTotal\n\nClaude Instant Inference\n5000\n$0.0008\n$0.004\n15000\n$0.0024\n$0.036\n100\n \n$0.80\n$0.82\n\nClaude 2.1 Inference\n5000\n$0.0008\n$0.004\n20000\n$0.0024\n$0.048\n100\n \n$0.80\n$0.832\n\nTotal Charges: $0.82 + $0.832 = $1.652","reference_context":"Document 260: On-demand pricing An application developer submits a dataset for human-based model evaluation using Anthropic Claude 2.1 and Anthropic Claude Instant in the US East (N. Virginia) AWS Region. \nThe dataset contains 50 prompts, and the developer requires one worker to rate each prompt-response set (configurable in the evaluation job creation as \u201cworkers per prompt\u201d parameter).  There will be 50 tasks in this evaluation job (one task for each prompt-response set per each worker). The 50 prompts combine to 5000 input tokens, and the associated responses combine to 15,000 tokens for Anthropic Claude Instant and 20,000 tokens for Anthropic Claude 2.1.  The following charges are incurred for this model evaluation job:\n\n\n\n\n\nItem\nNumber of input tokens\nPrice per 1000 input tokens\nCost of input\nNumber of output tokens\nPrice per 1000 output tokens\nCost of output\nNumber of human tasks\nPrice per human task\nCost of human tasks\nTotal\n\n\nClaude Instant Inference\n5000\n$0.0008\n$0.004\n15000\n$0.0024\n$0.036\n\u00a0\n\u00a0\n\u00a0\n$0.04\n\nDocument 262: On-demand pricing An application developer submits a dataset for human-based model evaluation using Anthropic Claude 2.1 and Anthropic Claude Instant in the US East (N. Virginia) AWS Region.  The dataset contains 50 prompts, and the developer requires two workers to rate each prompt-response set (configurable in the evaluation job creation as \u201cworkers per prompt\u201d parameter). There will be 100 tasks in this evaluation job (1 task for each prompt-response set per each worker: 2 workers x 50 prompt-response sets = 100 human tasks).  The 50 prompts combine to 5000 input tokens, and the associated responses combine to 15000 tokens for Anthropic Claude Instant and 20000 tokens for Anthropic Claude 2.1.  The following charges are incurred for this model evaluation job: \n\n\n\n\n\nItem\nNumber of input tokens\nPrice per 1000 input tokens\nCost of input\nNumber of output tokens\nPrice per 1000 output tokens\nCost of output\nNumber of human tasks\nPrice per human task\nCost of human tasks\nTotal","conversation_history":[{"role":"user","content":"I need to evaluate a model using Anthropic Claude Instant and Anthropic Claude 2.1 in the US East (N. Virginia) AWS Region. The dataset contains 50 prompts and requires two workers to rate each prompt-response set."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":260,"topic":"Cloud-Based AI Model Pricing"}}
{"id":"36396168-0c5d-4dba-b0bd-f0cae05acf26","question":"What does that amount to?","reference_answer":"The total cost of the Claude Instant Inference service is $0.04.","reference_context":"Document 265: Item\nNumber of input tokens\nPrice per 1000 input tokens\nCost of input\nNumber of output tokens\nPrice per 1000 output tokens\nCost of output\nNumber of human tasks\nPrice per human task\nCost of human tasks\nTotal\n\n\nClaude Instant Inference\n5000\n$0.0008\n$0.004\n15000\n$0.0024\n$0.036\n\u00a0\n\u00a0\n\u00a0\n$0.04\n\n\nClaude 2.1 Inference\n5000\n$0.008\n$0.04\n20000\n$0.024\n$0.48\n\u00a0\n\u00a0\n\u00a0\n$0.52\n\n\nHuman Tasks\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n100\n$0.21\n$21.00\n$21.00\n\n\nTotal\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n$21.56\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS","conversation_history":[{"role":"user","content":"I'm interested in the total cost of the Claude Instant Inference service."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":265,"topic":"Cloud-Based AI Model Pricing"}}
{"id":"edd79eb2-df53-493d-bd36-dfc02b7fa493","question":"How can one do that?","reference_answer":"To get started with AWS, you can sign up for a free account to instantly access the AWS Free Tier, which provides free access to certain AWS services for 12 months. Once you have an account, you can start building in the AWS Management Console by signing in.","reference_context":"Document 21: Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDocument 163: Sign up for a free account \n         \n\nInstant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDocument 206: Instant get access to the AWS Free Tier.\n\n Sign up\u00a0\n\n\n\n\n\n\n\n\n           Start building in the console \n         \n\nGet started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nDocument 52: Get started building in the AWS management console.\n\n Sign in\u00a0\n\n\n\n\n\n\n\n\n\n\n\n\n  Sign In to the Console \n\n Learn About AWS\n\nWhat Is AWS?\nWhat Is Cloud Computing?\nAWS Accessibility\nAWS Inclusion, Diversity & Equity\nWhat Is DevOps?\nWhat Is a Container?\nWhat Is a Data Lake?\nWhat is Artificial Intelligence (AI)?\nWhat is Generative AI?\nWhat is Machine Learning (ML)?\nAWS Cloud Security\nWhat's New\nBlogs\nPress Releases\n\n\n\n Resources for AWS\n\nGetting Started\nTraining and Certification\nAWS Solutions Library\nArchitecture Center\nProduct and Technical FAQs\nAnalyst Reports\nAWS Partners\n\n\n\n Developers on AWS\n\nDeveloper Center\nSDKs & Tools\n.NET on AWS\nPython on AWS\nJava on AWS\nPHP on AWS\nJavaScript on AWS\n\n\n\n Help\n\nContact Us\nGet Expert Help\nFile a Support Ticket\nAWS re:Post\nKnowledge Center\nAWS Support Overview\nLegal\nAWS Careers\n\n\n\n\n\n\n\n  Create an AWS Account","conversation_history":[{"role":"user","content":"I am interested in getting started with AWS."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":21,"topic":"AWS Services and Resources"}}
{"id":"7e29e5d2-67c6-4de7-a08a-2e5ddf872f27","question":"Can you explain the underlying mechanism?","reference_answer":"The provided context does not contain any information about how GPT (Generative Pre-trained Transformer) works. The given text is about Amazon's Bedrock User Guide and does not mention GPT or how it functions.","reference_context":"Document 217: How does GPT work?","conversation_history":[{"role":"user","content":"I'm interested in understanding how GPT works."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":217,"topic":"Generative Pre-Trained Transformer (GPT) AI"}}
{"id":"e2f5a86d-85e8-4422-a936-254a38f9e309","question":"What is that difference?","reference_answer":"Discriminative models attempt to determine the relationship between known and unknown factors, while generative models try to predict features given a certain label and learn the distribution of different data features and their relationships.","reference_context":"Document 97: Traditional machine learning models were discriminative or focused on classifying data points. They attempted to determine the relationship between known and unknown factors. For example, they look at images\u2014known data like pixel arrangement, line, color, and shape\u2014and map them to words\u2014the unknown factor. Mathematically, the models worked by identifying equations that could numerically map unknown and known factors as x and y variables.\nGenerative models take this one step further. Instead of predicting a label given some features, they try to predict features given a certain label. Mathematically, generative modeling calculates the probability of x and y occurring together. It learns the distribution of different data features and their relationships.\nFor example, generative models analyze animal images to record variables like different ear shapes, eye shapes, tail features, and skin patterns. They learn features and their relations to understand what different animals look like in general. They can then recreate new animal images that were not in the training set.\nNext, we give some broad categories of generative AI models.\nDiffusion models","conversation_history":[{"role":"user","content":"I'm interested in understanding the key difference between discriminative and generative models."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":97,"topic":"Generative AI Applications"}}
{"id":"88434cac-3b5a-48b3-91ae-49ee6dc59131","question":"What are some examples of this technology being applied?","reference_answer":"Conversational AI can be used in a variety of use cases, such as customer service chatbots, virtual assistants, and conversational interfaces for various applications.","reference_context":"Document 128: What are some use cases of conversational AI?","conversation_history":[{"role":"user","content":"I'm interested in learning about the use cases of conversational AI."},{"role":"assistant","content":"How can I help you with that?"}],"metadata":{"question_type":"conversational","seed_document_id":128,"topic":"Conversational AI"}}
